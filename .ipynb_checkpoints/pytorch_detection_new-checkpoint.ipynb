{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w2z8q6eojd7eb4h7wfds"
   },
   "source": [
    "Detection commets coma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "py1kedl697iiqulus2l9kp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io.image import read_image\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rr2n61zvjqith0fo9gbab"
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "jdvto9p8jde00xfozw9t"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "def print_image(sample):\n",
    "    # for example:  print_image(train[2])\n",
    "    fig, ax = plt.subplots(figsize = (9,9))\n",
    "    \n",
    "    image = np.moveaxis(sample['image'].numpy(), 0, 2)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    print(sample['file_name'])\n",
    "    \n",
    "    x1_y1 = sample['x1_y1'].numpy()\n",
    "    x2_y2 = sample['x2_y2'].numpy()\n",
    "    \n",
    "    w = abs(x1_y1[0] - x2_y2[0])\n",
    "    h = abs(x1_y1[1] - x2_y2[1])\n",
    "    x = min(x1_y1[0],x2_y2[0])\n",
    "    y = min(x1_y1[1],x2_y2[1])\n",
    "    \n",
    "    ax.add_patch(patches.Rectangle((x,y),w,h,\n",
    "                                   fill=False, edgecolor='red', lw=2))\n",
    "    plt.show()\n",
    "\n",
    "def show_images_batch(batch):\n",
    "    img_list = batch['image']\n",
    "    x1_y1_list = batch['x1_y1']\n",
    "    x2_y2_list = batch['x2_y2']\n",
    "    label = batch['label']\n",
    "    files_name = batch['label']\n",
    "\n",
    "    show_list_images(img_list, x1_y1_list, x2_y2_list, label, files_name)\n",
    "\n",
    "def show_list_images(img_list, x1_y1_list, x2_y2_list, label, files_name):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20,20))\n",
    "    for i in range(len(img_list)):\n",
    "        ax = fig.add_subplot(4, 4, i+1)\n",
    "        image = np.moveaxis(img_list[i].cpu().detach().numpy(), 0, 2)\n",
    "        ax.imshow(image)\n",
    "        x1_y1 = x1_y1_list[i].cpu().detach().numpy()\n",
    "        x2_y2 = x2_y2_list[i].cpu().detach().numpy()\n",
    "\n",
    "        w = abs(x1_y1[0] - x2_y2[0])\n",
    "        h = abs(x1_y1[1] - x2_y2[1])\n",
    "        x = min(x1_y1[0],x2_y2[0])\n",
    "        y = min(x1_y1[1],x2_y2[1]) \n",
    "        \n",
    "        ax.add_patch(patches.Rectangle((x,y),w,h,\n",
    "                     fill=False, edgecolor='red', lw=2))\n",
    "        ax.set_title(files_name[i])\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xulvp07v42a5ibyg54o6aq"
   },
   "source": [
    "# 1 Dataset и Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cellId": "b4ybsykqj1h69wrvfm7ubx"
   },
   "outputs": [],
   "source": [
    "class СometDetectionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, xml_file, img_dir,\n",
    "                 shuffle=False, train=None,\n",
    "                 test_size=0.05, transform=None, augmentation_transform=None):\n",
    "        self.img_dir = img_dir \n",
    "        self.transform = transform\n",
    "        self.augmentation_transform = augmentation_transform\n",
    "        self.data = self._get_dataset_from_xml_cvat_file(xml_file,shuffle,train,test_size)    \n",
    "    \n",
    "    def _get_dataset_from_xml_cvat_file(self,xml_file, shuffle, train, test_size):\n",
    "        import xml.etree.ElementTree as ET\n",
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        df = pd.DataFrame(columns=['file_name','x1','y1','x2','y2','label'])\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for file_item in root.iter(tag='image'):\n",
    "\n",
    "            name_file = file_item.attrib['name']\n",
    "            box_info = file_item.findall('box')\n",
    "            if len(box_info)==0:\n",
    "                continue\n",
    "            else:\n",
    "                box_info = box_info[0]\n",
    "                x1 = float(box_info.get('xtl'))\n",
    "                y1 = float(box_info.get('ytl'))\n",
    "                x2 = float(box_info.get('xbr'))\n",
    "                y2 = float(box_info.get('ybr'))\n",
    "                df.loc[len(df),:] = [os.path.join(self.img_dir,name_file), x1, y1, x2, y2, 1]\n",
    "        # return all dataset\n",
    "        if train==None:\n",
    "            return df\n",
    "        # split dataset to train and test\n",
    "        train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle, random_state=42)\n",
    "        if train==True:\n",
    "            if not self.augmentation_transform==None:\n",
    "                # create dir for augment images\n",
    "                path_to_save_aug = os.path.join(self.img_dir + 'aug/')\n",
    "                if not os.path.exists(path_to_save_aug):\n",
    "                    os.mkdir(path_to_save_aug)\n",
    "                else:\n",
    "                    # clear previous images \n",
    "                    shutil.rmtree(path_to_save_aug)\n",
    "                    os.mkdir(path_to_save_aug)\n",
    "                    \n",
    "                df_aug = pd.DataFrame(columns=['file_name','x1','y1','x2','y2','label'])\n",
    "                for index, row in train_df.iterrows():\n",
    "                    \n",
    "                    image = cv2.imread(row.file_name)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    bboxes = [[row.x1, row.y1, row.x2, row.y2,1]]\n",
    "                    transformed = self.augmentation_transform(image=image, bboxes=bboxes)\n",
    "                    transformed_image = transformed['image']\n",
    "                    \n",
    "                    transformed_bboxes = transformed['bboxes']\n",
    "                    (file_name, ext) = os.path.splitext(row.file_name)\n",
    "                    new_file_name = file_name.split('/')[-1] + ext\n",
    "                    new_file_name = os.path.join(path_to_save_aug, new_file_name)\n",
    "                    cv2.imwrite(new_file_name, transformed_image)\n",
    "                    df_aug.loc[len(df_aug),:] = [new_file_name,\n",
    "                                                     transformed_bboxes[0][0],transformed_bboxes[0][1],\n",
    "                                                     transformed_bboxes[0][2],transformed_bboxes[0][3],\n",
    "                                                     transformed_bboxes[0][4]]\n",
    "                if len(df_aug) > 0:\n",
    "                    train_df = pd.concat([train_df,df_aug])\n",
    "            return train_df.reset_index()\n",
    "        else:\n",
    "            return test_df.reset_index()\n",
    "        return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        result = {}\n",
    "        # get path to image\n",
    "        row = self.data.loc[idx]\n",
    "        #img_path = os.path.join(self.img_dir, row.file_name)\n",
    "        img_path = row.file_name\n",
    "        if os.path.exists(img_path):\n",
    "            # label studio change space to _ \n",
    "            image = read_image(img_path)\n",
    "            # if need do transform data\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            result['image'] = image\n",
    "            result['x1_y1'] = torch.FloatTensor([row.x1,row.y1])\n",
    "            result['x2_y2'] = torch.FloatTensor([row.x2,row.y2])\n",
    "            result['label'] = torch.LongTensor(row.label)\n",
    "        else:\n",
    "            result['image'] = None\n",
    "            result['x1_y1'] = None\n",
    "            result['x2_y2'] = None\n",
    "            result['label'] = None\n",
    "        # utility feacher for printing images \n",
    "        result['file_name'] = row.file_name\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cellId": "au71728k9dey2p27mstyi8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 190, test size 5\n"
     ]
    }
   ],
   "source": [
    "aug_transform = A.Compose([\n",
    "                           A.RandomSizedBBoxSafeCrop(width=250, height=250),\n",
    "                           A.HorizontalFlip(p=0.5),\n",
    "                           A.RandomBrightnessContrast(p=0.2),\n",
    "                         ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
    "\n",
    "train = СometDetectionDataset(xml_file = 'annotations2.xml', img_dir='./resize_images/',\n",
    "                              train=True, augmentation_transform = aug_transform)\n",
    "test = СometDetectionDataset(xml_file = 'annotations2.xml', img_dir='./resize_images/', train=False)\n",
    "print(f'Train size {len(train)}, test size {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hgkccdzmgmcpwuzfivbpqr"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=8, drop_last=True )\n",
    "test_loader = DataLoader(test, batch_size=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tjw8cd2w258rerpk1y29g"
   },
   "outputs": [],
   "source": [
    "# check if all images and bounding in place\n",
    "show_images_batch(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "cjhc326gq9tg44k7dg8e6r"
   },
   "source": [
    "# 2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xx8t7wltgl37gcm7a27hn"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "net = resnet50(pretrained=True)\n",
    "net.fc = torch.nn.Linear(in_features=512, out_features=4, bias=True)\n",
    "\n",
    "loss_function_x1y1 = torch.nn.L1Loss()\n",
    "loss_function_x2y2 = torch.nn.L1Loss()\n",
    "#loss_function_bce = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fqv9e4h8rnnx27jb6ggq28"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "n_epoch = 500\n",
    "for epoch in tqdm(range(n_epoch),total=n_epoch):\n",
    "    net.train()\n",
    "    epoch_loss = 0.\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch['image']\n",
    "        x1_y1 = batch['x1_y1']\n",
    "        x2_y2 = batch['x2_y2']\n",
    "        labels = batch['label']\n",
    "        images = images.to(device,dtype=torch.float)\n",
    "        x1_y1 = x1_y1.to(device)\n",
    "        x2_y2 = x2_y2.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = net(images)\n",
    "\n",
    "        loss = (loss_function_x1y1(predictions[:, :2], x1_y1) + \\\n",
    "               loss_function_x2y2(predictions[:, 2:4], x2_y2))\n",
    "               # + loss_function_bce(predictions[:, :10], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f'Train: loss = {epoch_loss / len(train_loader)}')\n",
    "\n",
    "torch.save(net, 'comet_detection_resnet_50')\n",
    "\n",
    "net.eval()\n",
    "epoch_loss = 0.\n",
    "for batch in test_loader:\n",
    "    # batch data to cuda\n",
    "    images = batch['image']\n",
    "    x1_y1 = batch['x1_y1']\n",
    "    x2_y2 = batch['x2_y2']\n",
    "    labels = batch['label']\n",
    "    files_name = batch['file_name']\n",
    "    \n",
    "    images = images.to(device,dtype=torch.float)\n",
    "    x1_y1 = x1_y1.to(device)\n",
    "    x2_y2 = x2_y2.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    \n",
    "    predictions = net(images)\n",
    "    \n",
    "    x1_y1_pred = predictions[:, :2]\n",
    "    x2_y2_pred = predictions[:, 2:4]\n",
    "    # calc loss\n",
    "    with torch.no_grad():\n",
    "        loss = 0.5*(loss_function_x1y1(x1_y1_pred, x1_y1) + \\\n",
    "               loss_function_x2y2(x2_y2_pred, x2_y2))\n",
    "                #+ loss_function_bce(predictions[:, :10], labels)\n",
    "    epoch_loss += loss.item()\n",
    "    # show detect bounding box\n",
    "    show_list_images(batch['image'], x1_y1_pred, x2_y2_pred, labels, files_name)\n",
    "\n",
    "print(f'Test: loss function {epoch_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ucp0jajnsjtn1opyzhxb5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "f1ac2974-34c2-496e-9f3f-ced7b3a9fecf"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
